%%%%%%%%%%%%%%%%%%%%%%% file template.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is a general template file for the LaTeX package SVJour3
% for Springer journals.          Springer Heidelberg 2010/09/16
%
% Copy it to a new file with a new name and use it as the basis
% for your article. Delete % signs as needed.
%
% This template includes a few options for different layouts and
% content for various journals. Please consult a previous issue of
% your journal as needed.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% First comes an example EPS file -- just ignore it and
% proceed on the \documentclass line
% your LaTeX will extract the file if required
\begin{filecontents*}{example.eps}
%!PS-Adobe-3.0 EPSF-3.0
%%BoundingBox: 19 19 221 221
%%CreationDate: Mon Sep 29 1997
%%Creator: programmed by hand (JK)
%%EndComments
gsave
newpath
  20 20 moveto
  20 220 lineto
  220 220 lineto
  220 20 lineto
closepath
2 setlinewidth
gsave
  .4 setgray fill
grestore
stroke
grestore
\end{filecontents*}
%
\RequirePackage{fix-cm}
%
%\documentclass{svjour3}                     % onecolumn (standard format)
%\documentclass[smallcondensed]{svjour3}     % onecolumn (ditto)
\documentclass[smallextended]{svjour3}       % onecolumn (second format)
%\documentclass[twocolumn]{svjour3}          % twocolumn
%
\smartqed  % flush right qed marks, e.g. at end of proof
%
\usepackage{graphicx}
%\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
%
\usepackage[backend=bibtex]{biblatex}
\addbibresource{pepr-pub.bib}
<<setup, include=FALSE, cache=FALSE, echo=FALSE>>=
Sys.setenv(TEXINPUTS=getwd(),
           BIBINPUTS=getwd(),
           BSTINPUTS=getwd())
@

% \usepackage{mathptmx}      % use Times fonts if available on your TeX system
%
% insert here the call for the packages your document requires
%\usepackage{latexsym}
% etc.
%
% please place your own definitions here and don't use \def but
% \newcommand{}{}
%
% Insert the name of "your journal" with
\journalname{Analytical and Bioanalytical Chemistry}
%
%
\begin{document}
%\SweaveOpts{concordance=TRUE}

\title{PEPR: Pipelines for Evaluating Prokaryotic References}

%\titlerunning{Short form of title}        % if too long for running head

\author{Nathan D. Olson \and
        Justin M. Zook \and
        Daniel V. Samarov \and
        Scott A. Jackson \and
        Marc L. Salit
}

%\authorrunning{Short form of author list} % if too long for running head

\institute{N. Olson \at
              Biosystems and Biomaterials Division, Material Measurement Laboratory, National Institute of Standards and Technology, Gaithersburg, MD, USA \\
              Tel.: +123-45-678910 +1-301-975-4873\\
              \email{nolson@nist.gov} 
           \and
           J. Zook \at
              Biosystems and Biomaterials Division, Material Measurement Laboratory, National Institute of Standards and Technology, Gaithersburg, MD, USA \\
              \email{justin.zook@nist.gov}
           \and
           D. Samarov \at
              Statistical Engineering Division, Information Technology Laboratory, National Institute of Standards and Technology, Gaithersburg, MD, USA \\
              \email{daniel.samarov@nist.gov}
          \and
           S. Jackson \at
              Biosystems and Biomaterials Division, Material Measurement Laboratory, National Institute of Standards and Technology, Gaithersburg, MD, USA \\
              \email{scott.jackson@nist.gov}
          \and
           M. Salit \at
              Biosystems and Biomaterials Division, Material Measurement Laboratory, National Institute of Standards and Technology, Gaithersburg, MD, USA \\
              Department of Bioengineering, Stanford University, Stanford, CA, USA
              \email{msalit@nist.gov}
}

\date{Received: date / Accepted: date}
% The correct dates will be entered by the editor


\maketitle
<< echo = FALSE, message=FALSE>>=
library(png)
library(grid)
library(dplyr)
library(ggplot2)
library(knitr)
library(kfigr)
library(peprr)
library(xtable)
source("rm_metadata.R")
source("calc_results_values.R")
peprDB <- dplyr::src_sqlite(db_path)
opts_chunk$set(message=FALSE, warning=FALSE, echo = FALSE)
@

\begin{abstract}
The rapid adoption of microbial whole genome sequencing in public health, clinical testing, and forensic laboratories requires the use of validated and well characterized measurement processes. Reference materials that are well characterized, homogeneous, and stable can be used to evaluate measurement processes and help to establish confidence in the results. Given the variety of microbial genome sequencing applications and platforms, as well as the vast microbial genomic diversity, there is a need for application-specific genomic materials for method validation. We have developed a reproducibile and transparent bioinformatics tool for characterize prokaryotic genomic materials; "PEPR", Pipelines for Evaluating Prokaryotic References. We demonstrate the tool and its output using a candidate reference material based on genomic material from \emph{Staphylococcus aureus}.

%% add results, conclusions/ impact statement

\keywords{Microbiology \and Whole genome sequencing \and Bioinformatics}
% \PACS{PACS code1 \and PACS code2 \and more}
% \subclass{MSC code1 \and MSC code2 \and more}
\end{abstract}

\section{Introduction}
\label{intro}
Over the past decade, the availability of affordable and rapid Next-Generation Sequencing (NGS) technology has revolutionized the field of microbiology. Arguably the most discriminatory typing method available, whole genome sequencing (WGS), has been adopted not only by the research community, but also by public health laboratories, clinical testing laboratories, and the forensic community. High stakes decisions are often made based on the outcome of a WGS assay. To increase confidence in WGS assay results a critical assessment of the errors inherent to the measurement processes is required. A number of sources of error associated with the WGS measurement process have been identified, but the degree to which they can be predicted, controlled or compensated varies significantly \cite{Olson2015}. 

Well-characterized, homogeneous, and stable genomic materials can be used to evaluate methods and aid in establishing confidence in results from a measurement process. For example, we recently characterized a whole human genome reference material (National Institute of Standards and Technology, NIST, Reference Material 8398) to assess performance of variant calling in human genomic samples \cite{Zook2014}, but no reference materials for microbial sequencing currently exist. Four microbial genomic DNA candidate reference materials are being developed at the National Institute of Standards and Technology (NIST) to meet this need. When considering the extensive genomic diversity present within prokaryotic organisms as well as the rapidly evolving and diverse DNA sequencing applications currently present, we envision the need for a wide variety of application-specific genomic materials for use in method validation and benchmarking. Currently, many laboratories and sequencing centers are using in-house materials as part of a regular method validation and quality control system. However, the degree to which these materials are characterized varies significantly, and therefore a common pipeline for characterizing prokaryotic genomic materials is needed.

“PEPR”, Pipelines for Evaluating Prokaryotic References, a set of reproducible and transperent bioinformatic pipelines, was developed to characterize genomic materials for use in WGS method validation. Application of the pipeline increases the confidence in method validation through the ability to develop better characterized control materials. The pipeline characterizes prokaryotic genomic material for purity and homogeneity of the genome sequence, as well as presence of genomic material other than the material genus. The general approach to material characterization that guided the development of PEPR is the use of orthogonal sequencing methods along with technical replicates to obtain consensus values for the characterized properties. These consensus values are our best current estimates of the true values. We do not assert probabilistic estimates of confidence or confidence classification values with the sequence data, as we lack good models of biases or systematic errors of current sequencing technologies. Here we will first describe PEPR then demonstrate the application of the pipelines using sequencing data generated for the genomic DNA \emph{Staphloyoccous aureus} NIST candidate reference reference material.

\section{Methods}
\label{methods}
\subsection{Pipelines for Evaluating Prokaryotic References: PEPR}
\label{method:1}
PEPR consists of three bioinformatic pipelines written in python (Fig. \ref{fig:workflowFig}).  The three bioinformatic pipelines are genome evaluation, genome characterization, and genomic purity. A YAML file (http://yaml.org) is used to define pipeline inputs. The pipeline coordinates the execution of a number of commandline tools, logging the standard output and standard error for each executed command in time-stamped files for reference and debugging. Pipeline code is available at (https://github.com/usnistgov/pepr). To reduce the barrier for reuse, two Docker (https://www.docker.com/) containers are available with pre-installed pipeline dependencies. Docker is a lightweight virtual environment that facilitates the sharing and distribution of computing environments and can be run on any desktop, cloud, or high performance computing environment, regardless of the operating system. The \texttt{pepr} container (https://registry.hub.docker.com/u/natedolson/pepr) includes dependencies for the genome evaluation and characterization pipelines, excluding the Genome Analysis Toolkit (due to licensing restrictions); a Dockerfile for building the container is included in the pepr github repository. The \texttt{docker-pathoscope} container (https://registry.hub.docker.com/u/natedolson/docker-pathoscope/) has dependencies for the genomic purity pipeline installed.

<< workflowFig, fig.aling = "center", fig.lp = "fig:", fig.cap= "PEPR workflow. White objects are pipeline inputs, grey objects are the three pipeline components, light blue objects are the pipeline products.">>=
grid.raster(readPNG("pepr-workflow.png"))
@

A software package, \texttt{peprr}, was developed for the statistical computing language R to compile the output from the genome evaluation, characterization, and genomic purity pipelines \cite{R2015}. The compiled data was formated into a series of data tables within a SQLite database to facilitate downstream analysis \cite{wickham2014tidy}.  The package includes functions to generate a number of summary tables and figures, including those in this publication.

\subsection{Genome Evaluation Pipeline}
\label{method:2}
The Genome Evaluation Pipeline, \texttt{evaluation}, is the first step in the PEPR workflow, and is used to reduce errors in the user provided genome assembly prior to characterization. The \texttt{evaluation} pipeline consists of three steps.  Illumina sequencing data are retrieved from the Genbank Sequence Read Archive (SRA) using the sratoolkit \texttt{fastq-dump} (http://ncbi.github.io/sra-tools/). Next, sequencing reads are mapped to the reference genome using BWA mem algorithm \cite{Li2013c}. Finally, Pilon is used to evaluate and polish the reference assembly \cite{Walker2014}. The corrected reference genome is then used as input for the Genome Characterization Pipeline.

\subsection{Genome Characterization Pipeline}
\label{method:3}
The Genome Characterization Pipeline uses replicate sequence dataset from multiple sequencing platforms to characterize the corrected reference genome produced by the \texttt{evaluation} pipeline at the individual base level. Illumina data are aligned to the reference genome using the same methods as the \texttt{evaluation} pipeline. Additionally, Pacific Biosciences sequencing data is mapped to the reference genome using the BWA mem algorithm \cite{Li2013c} and IonTorrent PGM data using the TMAP algorithm \cite{Homer}. Next the sequence alignment files are processed prior to downstream analysis by marking duplicates with Picard's MarkDuplicates (http://broadinstitute.github.io/picard) and realigning reads mapping to regions with insertions or deleltion using the GenomeAnalysisToolKit \cite{McKenna2010, DePristo12011}. After refining the alignment files, base level analysis is performed using the short read sequencing data.  For each platform a VCF (variant call format) file with a number of summary statistics is generated using SAMtools mpileup \cite{Li2009}. A base purity metric is calculated from the resulting VCF files. The base purity metric is the number of bases in reads aligned to a genome position that are in agreement with the reference base divided by the total number of reads aligned to the position. Homogeneity analysis, a measure of genomic content similarity between vials of the reference material, is performed by first generating a pileup file for each dataset then performing pairwise tumor-normal variant calling using VarScan \cite{Koboldt2009}. In this work, VarScan looks specifically for differences between vials in the proportion of reads containing variants. A standard Benjamini-Hochberg procedure was used to assess the power of the homogeneity analysis (Supplemental Material, https://github.com/DanSBS/NGSPower).  Additionally, a number of summary statistics are calculated for the sequencing datasets using Picard's Collect Multiple Metrics (http://broadinstitute.github.io/picard).  

\subsection{Genome Purity Pipeline}
\label{method:4}
The purity of the genomic material, in terms of the presence of DNA from sources other than the expected genus was assessed using the metagenomic taxonomic read classification algorithm PathoScope 2.0 \cite{Hong2014}.  This method uses an expectation maximization algorithm where the sequence data are first mapped to a database comprised of all sequence data in the Genbank nt database. Then, through an iterative process PathoScope re-assigns ambiguously mapped reads to a taxonomic group based on the proportion of reads mapped unambiguously to individual taxonomic groups in the database. Using short read sequencing data as input PathoScope first filters and trims low quality reads (PathoQC), followed by mapping reads to a reference database (PathoMap - a wrapper for bowtie2 \cite{Langmead2012}), then an expectation-maximization classification algorithm (PathoID).  The annotated Genbank nt database provided by the PathoScope developers was used as the reference database (ftp://pathoscope.bumc.bu.edu/data/nt\_ti.fa.gz). 

\subsection{Candidate Reference Material \emph{S. aureus} Sequencing Data}
.... Used to demonstrate RM

\section{Results}
The results for the demonstration application are presented below ....

%%% same read lenghts - include min, max or other statistic?
\subsection{Sequencing Data Summary Statistics}
Summary statistics were calculated for the number of reads, mapped read length, insert size for paired-end datasets as well as coverage for \emph{S. aureus} datasets (Table \ref{Table:seqTable}). The MiSeq sequencing run had an average of  \Sexpr{round(mean_miseq_library_read_count/2000000, digits = 1)} million paired-end reads per library with a median read length of  \Sexpr{miseq_med_read_length} bp,  whereas the PGM sequencing run produced \Sexpr{round(mean_pgm_library_read_count/2000000, digits = 1)} million reads per library on average with a median read length of \Sexpr{pgm_med_read_length} bp.  The higher throughput of MiSeq resulted in a higher per-library coverage for MiSeq compared to PGM (\Sexpr{paste0(as.character(mean_miseq_library_coverage),"X")} vs. \Sexpr{ paste0(as.character(mean_pgm_library_coverage),"X")}).  The three PacBio datasets are technical sequencing replicates (SMRT cells) from the same sequencing library, with a median subread length \Sexpr{paste0(as.character(pacbio_med_read_length),"bp")} and \Sexpr{paste0(as.character(pacbio_total_coverage),"X")} total coverage. Between the three platforms a total coverage of \Sexpr{paste0(as.character(total_coverage),"X")} was obtained.

<< seqTable, results='asis' >>=
xtable(seq_summary_table(peprDB), label = "Table:seqTable",digits = 0,
      # round = 0, 
      row.names = FALSE, caption = "Summary of sequencing datasets")
@

\subsection{Genome Evaluation}
The first step in PEPR is the Genome Evaluation Pipeline.  Short read sequencing data is used to identify and correct errors in the user-provided reference genome, in this case the PacBio HGAP assembly that was initially validated using the optical mapping data. Running Pilon using the MiSeq data did not identify any missassemblies or base call errors. 
%%% Pilon bed any ambiguous regions/ bases?


\subsection{Base Level Purity}
<<source_base_analysis, cache = TRUE>>=
source("base_purity_analysis.R")
@

A base purity metric was used to evaluate the degree to which the sequencing data supports the reference base call.  We compared purity metric values between two orthogonal sequencing methods for all positions in the genome (Fig. \ref{fig:purityScatterFig}). Positions with purity metric values greater than 99 \% were categorized as high purity and less than 99 \% low purity. Out of \Sexpr{total_pos} positions in the genome \Sexpr{pos_pur_gt99_both} positions had purity values greater than 99 \% for both short read sequencing platforms (Table \ref{Table:purityTable}).  Further, \Sexpr{pos_pur_gt99_one} and \Sexpr{ pos_pur_gt97_one} positions had purity values greater than 99 \% and 97 \%, respectively, for one of the two platforms.  Only \Sexpr{pos_pur_lt99_both} positions had a purity less than 99 \% for both platforms, and no positions had a purity value less than \Sexpr{min_max_pur_position} \% for both platforms. The positions with low purity for MiSeq were non-uniformly distributed whereas positions with low purity for PGM were uniformly distributed (Fig. \ref{fig:purityPositionFig}).  

<< purityTable, results="asis">>=
peprDB <- dplyr::src_sqlite(db_path)
pur_dat_id %>% group_by(pur_group) %>% summarise(count = n()) %>% xtable(row.names = NA,label = "Table:purityTable", caption = "Number of genome positions with high and low purity, positions purity metric values higher and lower than 0.99 respectively, for MiSeq and PGM sequencing platforms.")
@


<< purityScatterFig, fig.align='center', fig.lp = "fig:", fig.cap= "Comparison of base purity values for PGM and MiSeq. Positions are colored based of high and low purity values for the two sequencing platforms. A purity value of 0.99 was used to differentiate between high and low purity positions.">>=
ggplot2::ggplot(pur_dat_id_filt) +
     ggplot2::geom_point(ggplot2::aes(x = plat1, y = plat2, color = pur_group),
                         alpha = 0.5) +
     ggplot2::labs(x = "MiSeq", y = "PGM") + ggplot2::theme_bw() + 
     ggplot2::xlim(min_val, 1) + ggplot2::ylim(min_val, 1)
@

<< purityPositionFig, fig.align='center', fig.lp = "fig:", fig.cap= "Position of bases with low purity, (\textless 99 \%) for one or both of the two short read sequencing platforms.">>=
ggplot(pur_dat_id_filt %>% filter(CHROM == chrom_names[1])) + 
     geom_bar(aes(x = POS, fill = pur_group)) + 
     facet_wrap(~pur_group, ncol = 1, scales = "free_y") + theme_bw()
@

\subsubsection{Base Level Homogeneity}
The genomic material homogeneity was assessed through pairwise statistical analysis of the replicate MiSeq datasets using the VarScan somatic variant caller \cite{Koboldt2009}.  The pairwise variant analysis failed to identify any statistically significant base level differences among the replicates (Table \ref{Table:homogeneityTable}). Based on results from the power analysis .....


<< homogeneityTable, results = "asis">>=
xtable(homogeneity_sig_table(peprDB, rename_cols = TRUE),
       label = "Table:homogeneityTable",
       row.names = FALSE,
       caption = "Pairwise variant analysis results")
@


\subsection{Genomic Purity Pipeline}
Short read sequencing data was used to identify the proportion of DNA in the material from an organism other than the material genus, in this case \emph{Staphylococcus}, using PathoScope 2.0 \cite{Hong2014} . Based on analysis of the MiSeq and PGM sequencing data, the reference material has minimal if any genomic contaminants (Fig. \ref{fig:contamCountsFig}), with a maximum of \Sexpr{max_contam} reads in any dataset classified as not belonging to the genus \emph{Staphylococcus}. The most abundant contaminant was \emph{Escherichia coli} (Fig. \ref{fig:contamTaxaFig}).  


<<contamCountsFig, fig.align = "center", fig.lp = "fig:", fig.cap= "Proportion of reads from contaminant DNA.Reads categorized as genomic contaminants as classified by PathoScope as not beloning to the genus Staphylococcus.">>=
contam_counts_figure(peprDB, rm_genus)
@


<<contamTaxaFig, fig.align = "center", fig.lp = "fig:", fig.cap= "Breakdown of contaminants by organism.">>=
contam_point_line_figure(peprDB, rm_genus)
@

\section{Discussion}
\subsection{PEPR}
Pipelines for Evaluating Prokaryotic References (PEPR) is designed to use biological and technical replicate sequencing data from orthogonal sequencing platforms to characterize the genome of a microbial material.  There are two primary reasons for using replicate sequencing datasets one is to test for homogeneity within the batch of DNA being characterized the second is to minimize the impact of library specific biases. Note that in the experimental design for \emph{S. aureus}, Ion Torrent sequencing the library specific biases and variability between replicate vials are confounded, but not for the Illumina data as replicate libraries were performed for each of the eight vials. The resulting characterized genome is suitable for use in evaluating and benchmarking whole genome sequencing methods. PEPR consists of three pipelines: genome evaluation, genome characterization, and genomic purity assessment.

The Genome Evaluation Pipeline in the PEPR provides an automated method for evaluating and refining a reference genome sequence. User's provide a high quality reference genome as input to the pipeline. Pilon was chosen for the genome evaluation step as it not only assesses the accuracy of the genome but also corrects errors in the assembly.  Other methods are available for evaluating reference genomes, e.g. amosValidate \cite{Phillippy2008} and ALE \cite{Clark2013}, however these methods only assess assembly accuracy and do not correct missassemblies. The resulting reference assembly represents a consensus genome for the population of cells used to generate the material being characterized.  The genome evaluation pipeline does not attempt to identify or characterize low frequency structural variants within the material or vial-to-vial variability of the reference genome. The reference genome, once validated and if nessessary refined by the Genome Evaluation Pipeline, is then used as input for the Genome Characterization Pipeline. 

The Genome Characterization Pipeline calculates base level statistics using replicate sequencing data from orthogonal measurement methods.  Additionally, the Genome Characterization Pipeline generates summary statistics for the sequencing datasets used in the material characterization procedure as well as long read data if it was used to generate the reference assembly.  The results from the Genome Evaluation and Characterization pipeline are loaded into peprDB, an SQLite database. Loading the data into a SQLite database makes it easier to perform additional analyses of the material characterization and evaluation results.

If another lab wishes to characterize a new reference or quality control material, they could follow this process:
\begin{enumerate}
    \item Ideally, the user should generate a large batch of material and aliquot it to reduce inhomogeneity.
    \item Identify a high-quality genome assembly. If a good reference assembly does not exist for the sample, then long-read sequencing like PacBio may be required to generate an assembly, and ideally mapping technologies would be used to validate the assembly.
    \item Short-read whole genome sequencing, preferably from two orthogonal sequencing technologies, should be generated from multiple vials of the material, ideally 2 technical replicate libraries from at least six randomly selected vials.
    \item PEPR can then be run to assess base-level purity and homogeneity, genomic contaminants, and mis-assemblies.
The methods presented in this work provide a straightforward pipeline that can be used by any laboratory to characterize new reference materials or in-house quality controls.
\end{enumerate}

\subsection{PEPR Application: Characterization of Candidate RM 8376 using PEPR}
\subsubsection{Preparation of Reference Assembly}
PEPR requires a high quality reference assembly for input, in this work, the closed candidate reference genome was assembled from long read data generate using the Pacific Biosciences RSII platform was used. To validate the reference genome, whole genome mapping data generated with the OpGen optical mapping technology, an orthogonal measurement method, was used to evaluate the genome assembly. Optical mapping results were used to assess the overall structure of the genome. The long DNA fragments (average size \textgreater 200Mb) allow for the evaluation of large misassemblies (\textless 3 kb) that are not easily identified using standard short read sequencing data \cite{Mendelowitz2014}.  Optical mapping technologies and large insert mate-pair library preparation methods, including Illumina's TruSeq Synthetic Long-Reads \cite{McCoy2014}, represent orthogonal methods that can also be used to identify large misassemblies for validating reference assemblies for use in PEPR.  In this work, after using optical mapping to validate that no large misassemblies existed, the reference assembly from PacBio was used as input for the PEPR. 

\subsubsection{Sequencing Dataset Summary}
The PEPR database (peprDB) includes a number of summary statistics for the sequencing datasets processed.  For sequencing datasets used to characterize the NIST candidate reference material RM8376, throughput and read lengths were as expected based on the library prep and sequencing methods used excluding the PGM datasets. For PGM the 400 bp sequencing and library preparation methods, median read lengths of \Sexpr{pgm_med_read_length} bp. The shorter read length is potentially due to the low GC content, which is known to challenge current sequencing technologies \cite{Quail2012}.  

\subsubsection{Base Level Purity}
The ratio of sequencing reads supporting the reference base call and alternative base call were used to assess the purity of a genome position or base in the material as a whole. Through comparison of the base purity for two orthogonal sequencing methods we identified genome positions with low purity values due to platform specific systematic sequencing errors. The reference base is identified using a third orthogonal sequencing method (Pacific Biosciences RSII), which only chooses the dominant base and does not identify small impurities. Thus, a low purity (below 50 \%) for one of the two short read sequencing platforms and a high purity value for the other means that two technologies (one short read and one long read) agree that the dominant base is the reference base. It is also important to acknowledge that even if the two short read sequencing platforms indicate an impurity, they are potentially susceptible to the same unknown bias. The sequencing technologies used to characterize the material are still maturing and an incomplete understanding of platform specific biases limits our ability to provide a confidence value for the base calls. 

A number of base level metrics, such as strand bias, are calculated as part of the PEPR Genome Characterization Pipeline and are included in the pipeline results database. These metrics can be used to differentiate positions with low purity due to measurement error and those due to biological variability. Use of additional metrics and algorithms developed for the identification of low frequency variants, such as loFreq \cite{Wilm2012}, could help identify positions with low levels of biological variability, but are not currently implemented in PEPR. 

The PEPR Genome Characterization Pipeline assesses the homogeneity of a material through comparison of purity values between replicate vials.  The homogeneity analysis is performed using the varscan tumor-normal variant caller \cite{Koboldt2009}.  Only Illumina data was used to assess the homogeneity of the material as the higher coverage increased the statistical power of the test, and replicate libraries provide information regarding the method error rate.  The Ion Torrent dataset did not include replicate libraries for the eight vials sequenced and therefore library specific sequencing errors were confounded with vial to vial variability. No statistically significant variants were identified between all pairwise comparisons indicating that the material is homogeneous. If potential inhomogeneities were found, then the PGM sequencing data could be examined to see if it also has evidence for the inhomogeneities. Even without replicate libraries for the different vials it is unlikely that any library specific bias with correlate with vial-to-vial variability observed in the Illumina data by chance.

\subsection{Genomic Purity Pipeline}
 The Genomic Purity Pipeline is used to identify DNA within the material that belongs to a genus other than the material genus.  The genus level cutoff was selected based on results from a previous study characterizing the specificity of the PathoScope classification algorithm (Olson et al. \emph{in-prep}). Genomic contaminants can be from the culture itself or reagents and materials used to prepare the material \cite{Shrestha2013, Tang2003, Salter2014}.  Contaminants identified by the \texttt{genomic\_purity} pipeline may not be present in the material. For example reagents used during library preparation may also include contaminants \cite{Tanner1998, Newsome2004, Motley2014, Salter2014}.  Additionally, bioinformatic errors may lead to false positive contaminants, either due to errors in the database, sequence misclassification, or errors in the classification algorithm itself.  Genomic purity analysis of the \emph{S. aureus} material identified a number of candidate contaminants,  the most abundant of which was \emph{E. coli}.  \emph{E. coli} is a well documented contaminant of molecular biology reagents, and not likely a true contaminant \cite{Salter2014}. Lower abundant contaminants maybe bioinformatic errors and not true contaminants. While, contaminants identified by the Genomic Purity Pipeline are most likely from reagents and due to bioinformatic errors, a conservative estimate of the material purity, assuming all contaminants are real, is output from the pipeline. Users will want to take into consideration the limited specificity of the taxonomic classification method, the inability to identify contaminants at the strain and species level, when using PEPR to validate a material for there application.  For example if the intended use of the genomic DNA is for use as part of an inclusivity exclusivity pannel, additional genomic purity assessment in addition to the PEPR Genomic Purity Pipeline is required to validate the material.

\section{Conclusions}
PEPR provides a framework for characterizing microbial genomic reference materials, for instance using a homogenized batch of DNA from a single prokaryotic strain. The objective in developing PEPR was to provide a reproducible and transparent workflow for the characterization of prokaryotic genomic materials. The pipeline can be used to characterize reference materials as well as in-house quality control materials for which replicate sequencing datasets from multiple platforms is available. The outputs from running PEPR include a corrected reference genome assembly, identified genome position with high and low purity based on biological and technical variation, base level homogeneity of the material, as well as the percentage and identity of genus level genomic contaminants. The resulting characterization values are intentionally conservative and without uncertainty or confidence estimates, as sources of bias and error associated with the measurement process are currently not fully understood. As the scientific community's understanding of the measurement process matures new algorithms can be incorporated into the pipeline to increase the quality of material characterization results. The use genomic materials characterized using PEPR will not only help increase the confidence in the measurement methods and assays the materials are used to benchmark and validate but also improve our understanding of sequencing and analysis methods.


\begin{acknowledgements}
The author’s would like to thank Jenny McDaniel, Lindsay Vang, and David Catoe for performing the MiSeq and PGM sequencing, and Tim Muruvanda for performing the PacBio sequencing. This work was supported by the Department of Homeland Security (DHS) Science and Technology Directorate under the Interagency Agreement HSHQPM-14-X-00078 with NIST and by two interagency agreements with the FDA. Opinions expressed in this paper are the authors’ and do not necessarily reflect the policies and views of the DHS, NIST, or affiliated venues. Certain commercial equipment, instruments, or materials are identified in this paper only to specify the experimental procedure adequately. Such identification is not intended to imply recommendation or endorsement by the NIST, nor is it intended to imply that the materials or equipment identified are necessarily the best available for the purpose.
Official contribution of NIST; not subject to copyrights in USA.
\end{acknowledgements}

% % BibTeX users please use one of
%\bibliographystyle{spbasic}      % basic style, author-year citations
% %\bibliographystyle{spmpsci}      % mathematics and physical sciences
% %\bibliographystyle{spphys}       % APS-like style for physics
% \bibliography{pepr-pub}   % name your BibTeX data base
\printbibliography

\end{document}
% end of file template.tex

